# dataset reference : https://www.kaggle.com/datasets/loveall/appliances-energy-prediction

###Downloading all the library required for the project
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing, model_selection, metrics
 


from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from  sklearn.linear_model import Ridge
import warnings
warnings.filterwarnings("ignore")
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Lasso
from  sklearn.preprocessing  import PolynomialFeatures
%matplotlib inline
import matplotlib.pyplot as plt

import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import ElasticNet
from sklearn.svm import SVR
from sklearn.svm import LinearSVR


from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

data = pd.read_csv('./energy_consumption.csv')
data.head()

# Features to be removed from the input dataset
# Date, Light, 

data.info()
# rows : 19734   Col : 29

#Function to convert categorical data to label encoding(We are not using Onehot encoders as the variable is ordinal)
def conditions(df):
    if (df['Tdewpoint']== 'LDT'):
        return 0
    elif (df['Tdewpoint']== 'ADT'):
        return 1
    elif (df['Tdewpoint']== 'NDT'):
        return 2
    else:
        return 3    

data['Tdewpoint']= data.apply(conditions, axis=1)

data.head()

# Missing values
pd.DataFrame(data.isna().sum(), columns=["records missing"]).T

# drop the col - date and light
data= data.drop('lights', axis=1)

data= data.drop('date', axis=1)

data.head(3)

## Divide the columns based on type for clear column management 

col_temp = ["T1","T2","T3","T4","T5","T6","T7","T8","T9"]

col_hum = ["RH_1","RH_2","RH_3","RH_4","RH_5","RH_6","RH_7","RH_8","RH_9"]

col_weather = ["T_out", "Tdewpoint","RH_out","Press_mm_hg",
                "Windspeed","Visibility"] 

col_randoms = ["rv1", "rv2"]

col_target = ["Appliances"]

# Seperate dependent and independent variables 
feature_vars = data[col_temp + col_hum + col_weather + col_randoms] 
target_vars = data[col_target]

feature_vars.describe()

target_vars.describe()

# Histogram of all the features to understand the distribution
feature_vars.hist(bins = 20 , figsize= (12,16)) ;

# I took a sbupart of the data for analysis as it was giving memory error and was very slow for such large dataset
x= feature_vars.iloc[:1200,:]
y= target_vars.iloc[:1200,:]

scaler= StandardScaler()
x=scaler.fit_transform(x)

x_train, x_test, y_train, y_test= train_test_split(x,y, random_state=0)

compiled= pd.DataFrame(columns= ['Regressor',  'RMSE','R2Score','MAPE', 'Accuracy'])

### Regresion

# lreg= LinearRegression()
# lreg.fit(x_train, y_train)

from sklearn.linear_model import LinearRegression
lreg= LinearRegression()

lreg.fit(x_train,y_train)
print(f'Train score for Linear regression model without using Kfold validation is: {lreg.score(x_train, y_train)}')

train_scores= cross_val_score(lreg,x_train,y_train, cv=10)
print(f'Train score for Linear regression model using 10Fold cross validation is:  {train_scores.mean()}')
test_scores= cross_val_score(lreg,x_test,y_test, cv=10)
print(f'Test score for Linear regression model using 10Fold cross validation is:  {test_scores.mean()}')

pred = lreg.predict(x_test)
r2_score_lr = r2_score(pred,y_test)
print("R2Score on Linear regression set: ", r2_score_lr)

mse= cross_val_score(lreg, x_train, y_train, scoring="neg_mean_squared_error", cv=10)
print(f'RMSE for Linear regression model using 10Fold cross validation is: {mse.mean()}')

def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true))

## Check condition of Overfitting/Underfitting

# ## testing data:
# test_pred = ridge_model.predict(X_test)
mape_test = round(mean_absolute_percentage_error(y_test, pred), 4)
acc_test = round((1-mape_test)*100, 2)


print(f"{'Mean Absolute Percentage Error (MAPE) on test set'.ljust(70)} : {mape_test}\n")


print(f"{'Accuracy (1-MAPE) on test set'.ljust(70)} : {acc_test}%")

compiled=compiled.append({'Regressor': 'Linear Regression',  'RMSE': mse.mean(),
                          'R2Score' : r2_score_lr,
                          "MAPE": mape_test,"Accuracy" : acc_test}, ignore_index=True)

compiled
